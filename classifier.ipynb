{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get new model...\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "import os\n",
    "import re\n",
    "import codecs\n",
    "import gensim\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scripts.testWord2Vec import model\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def getWordVecs(words):\n",
    "    vecs = []\n",
    "    for word in words:\n",
    "        word = word.replace('\\n', '')\n",
    "        try:\n",
    "            if ruwiki_model.model_word_from_word.get(word) != None:\n",
    "                vecs.append(ruwiki_model.model[ruwiki_model.model_word_from_word[word]].reshape((1,300)))\n",
    "        except KeyError:\n",
    "            continue\n",
    "    vecs = np.concatenate(vecs)\n",
    "    return np.array(vecs, dtype='float') #TSNE expects float type values\n",
    "\n",
    "def getNewWordVecs(words):\n",
    "    vecs = []\n",
    "    for word in words:\n",
    "        word = word.replace('\\n', '')\n",
    "        try:\n",
    "            if new_model.get(word) != None:\n",
    "                vecs.append(new_model[word].reshape((1,300)))\n",
    "        except KeyError:\n",
    "            continue\n",
    "    vecs = np.concatenate(vecs)\n",
    "    return np.array(vecs, dtype='float') #TSNE expects float type values\n",
    "    \n",
    "def load_model(file_name):\n",
    "    # TODO: it's for current implementation\n",
    "    dir_name = os.path.dirname(os.path.realpath('__file__'))\n",
    "    name = os.path.join(*[dir_name, '..', file_name])\n",
    "    the_model = model(name)\n",
    "    return the_model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ------------ web --------------------\n",
    "    #web_model_size = 353608\n",
    "    #web_model_file_name = 'web.model.bin'\n",
    "    \n",
    "    # ------------ news ------------------\n",
    "    #news_model_size = 124590\n",
    "    #news_model_file_name = 'news.model.bin'\n",
    "\n",
    "    # ---------- ruscorpora -------------\n",
    "    #rus_model_size = 184973\n",
    "    #rus_model_file_name = 'ruscorpora.model.bin'\n",
    "\n",
    "    # ---------- ruwikiruscorpora -------------\n",
    "    ruwiki_model_size = 392339\n",
    "    ruwiki_model_file_name = 'ruwikiruscorpora.model.bin'\n",
    "    ruwiki_model = load_model(ruwiki_model_file_name)\n",
    "    \n",
    "\n",
    "    dir_name = os.path.dirname(os.path.realpath('__file__'))\n",
    "    pref_file_path = os.path.join(*[dir_name, 'dicts', 'prefixes.txt'])\n",
    "    suff_file_path = os.path.join(*[dir_name, 'dicts', 'suffixes.txt'])\n",
    "    finTerms_file_path = os.path.join(*[dir_name, 'dicts', 'finTerms.txt'])\n",
    "    medTerms_file_path = os.path.join(*[dir_name, 'dicts', 'med200Terms.txt'])\n",
    "    avtoTerms_file_path = os.path.join(*[dir_name, 'dicts', 'avto200Terms.txt'])\n",
    "    \n",
    "    new_model = ruwiki_model.get_new_morphemes_model(pref_file_path, suff_file_path)\n",
    "    \n",
    "    with codecs.open(finTerms_file_path, 'r', encoding='utf-8') as infile:\n",
    "        fin_words = infile.readlines()\n",
    "    \n",
    "    with codecs.open(medTerms_file_path, 'r', encoding='utf-8') as infile:\n",
    "        med_words = infile.readlines()\n",
    "    \n",
    "    with codecs.open(avtoTerms_file_path, 'r', encoding='utf-8') as infile:\n",
    "        avto_words = infile.readlines()\n",
    "        \n",
    "    fin_vecs = getWordVecs(fin_words)\n",
    "    for vec in fin_vecs:\n",
    "        with codecs.open('fin_vects.txt', 'a', encoding='utf-8') as outfile:\n",
    "                outfile.write(str(vec).decode('utf-8'))\n",
    "                outfile.write('\\n')\n",
    "    \n",
    "    med_vecs = getWordVecs(med_words)\n",
    "    for vec in med_vecs:\n",
    "        with codecs.open('med_vects.txt', 'a', encoding='utf-8') as outfile:\n",
    "                outfile.write(str(vec).decode('utf-8'))\n",
    "                outfile.write('\\n')\n",
    "\n",
    "    avto_vecs = getWordVecs(avto_words)\n",
    "    for vec in med_vecs:\n",
    "        with codecs.open('avto_vects.txt', 'a', encoding='utf-8') as outfile:\n",
    "                outfile.write(str(vec).decode('utf-8'))\n",
    "                outfile.write('\\n')\n",
    "                \n",
    "    fin_vecs = np.nan_to_num(fin_vecs)\n",
    "    med_vecs = np.nan_to_num(med_vecs)\n",
    "    avto_vecs = np.nan_to_num(avto_vecs)\n",
    "    \n",
    "    ts = TSNE(2)\n",
    "    reduced_vecs = ts.fit_transform(np.concatenate((fin_vecs, med_vecs, avto_vecs)))\n",
    "    #reduced_vecs = ts.fit_transform(fin_vecs)\n",
    "    \n",
    "    #color points by word group to see if Word2Vec can separate them\n",
    "    for i in range(len(reduced_vecs)):      \n",
    "        if i < len(fin_vecs):\n",
    "            color = 'b'\n",
    "        elif i >= len(fin_vecs) and i < (len(fin_vecs) + len(med_vecs)):\n",
    "            color = 'g'\n",
    "        else:\n",
    "            color = 'r'\n",
    "        #color = 'b'\n",
    "        plt.plot(reduced_vecs[i,0], reduced_vecs[i,1], marker='o', color=color, markersize=8)\n",
    "        plt.title('FIN (b) + MED (g) + AVTO TERMS (b)')\n",
    "    plt.show()\n",
    "    \n",
    "    # NEW MODEL\n",
    "    \n",
    "    new_fin_vecs = getNewWordVecs(fin_words)\n",
    "    for vec in fin_vecs:\n",
    "        with codecs.open('new_model_fin_vects.txt', 'a', encoding='utf-8') as outfile:\n",
    "                outfile.write(str(vec).decode('utf-8'))\n",
    "                outfile.write('\\n')\n",
    "    \n",
    "    new_med_vecs = getNewWordVecs(med_words)\n",
    "    for vec in med_vecs:\n",
    "        with codecs.open('new_model_med_vects.txt', 'a', encoding='utf-8') as outfile:\n",
    "                outfile.write(str(vec).decode('utf-8'))\n",
    "                outfile.write('\\n')\n",
    "\n",
    "    med_avto_vecs = getNewWordVecs(avto_words)\n",
    "    for vec in med_vecs:\n",
    "        with codecs.open('new_model_avto_vects.txt', 'a', encoding='utf-8') as outfile:\n",
    "                outfile.write(str(vec).decode('utf-8'))\n",
    "                outfile.write('\\n')\n",
    "                \n",
    "    new_fin_vecs = np.nan_to_num(new_fin_vecs)\n",
    "    new_med_vecs = np.nan_to_num(new_med_vecs)\n",
    "    new_avto_vecs = np.nan_to_num(new_avto_vecs)\n",
    "    \n",
    "    ts = TSNE(2)\n",
    "    new_reduced_vecs = ts.fit_transform(np.concatenate((new_fin_vecs, new_med_vecs, new_avto_vecs)))\n",
    "    \n",
    "    #color points by word group to see if new model can separate them\n",
    "    for i in range(len(new_reduced_vecs)):      \n",
    "        if i < len(new_fin_vecs):\n",
    "            color = 'b'\n",
    "        elif i >= len(new_fin_vecs) and i < (len(new_fin_vecs) + len(new_med_vecs)):\n",
    "            color = 'g'\n",
    "        else:\n",
    "            color = 'r'\n",
    "        #color = 'b'\n",
    "        plt.plot(new_reduced_vecs[i,0], new_reduced_vecs[i,1], marker='o', color=color, markersize=8)\n",
    "        plt.title(' NEW MODEL: FIN (b) + MED (g) + AVTO TERMS (b)')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
